{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using the 'coco128.yaml' dataset for 3 epochs\n",
    "#results = model.train(data='coco128.yaml', epochs=5)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "#results = model.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model to ONNX format\n",
    "success = model.export(format='pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6461.jpg: 480x640 1 person, 1 banana, 1 apple, 96.2ms\n",
      "Speed: 2.2ms preprocess, 96.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7964.jpg: 480x640 1 banana, 52.5ms\n",
      "Speed: 2.1ms preprocess, 52.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3653.jpg: 480x640 1 orange, 54.5ms\n",
      "Speed: 1.4ms preprocess, 54.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3121.jpg: 480x640 2 apples, 48.1ms\n",
      "Speed: 1.0ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4470.jpg: 480x640 1 apple, 1 orange, 48.3ms\n",
      "Speed: 1.2ms preprocess, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_5961.jpg: 480x640 2 apples, 49.4ms\n",
      "Speed: 0.9ms preprocess, 49.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3487.jpg: 480x640 1 apple, 1 dining table, 48.8ms\n",
      "Speed: 1.8ms preprocess, 48.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4317.jpg: 480x640 1 apple, 1 dining table, 1 laptop, 50.2ms\n",
      "Speed: 1.6ms preprocess, 50.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7144.jpg: 480x640 1 banana, 2 apples, 50.8ms\n",
      "Speed: 1.7ms preprocess, 50.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6528.jpg: 480x640 1 banana, 1 apple, 48.4ms\n",
      "Speed: 1.5ms preprocess, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3861.jpg: 480x640 1 apple, 51.5ms\n",
      "Speed: 0.9ms preprocess, 51.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3875.jpg: 480x640 1 banana, 1 apple, 53.3ms\n",
      "Speed: 1.7ms preprocess, 53.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7408.jpg: 480x640 1 banana, 1 apple, 1 orange, 1 vase, 49.5ms\n",
      "Speed: 1.7ms preprocess, 49.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4129.jpg: 480x640 1 bench, 1 sports ball, 2 apples, 1 orange, 49.3ms\n",
      "Speed: 1.6ms preprocess, 49.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6460.jpg: 480x640 1 banana, 1 apple, 48.8ms\n",
      "Speed: 0.9ms preprocess, 48.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3256.jpg: 480x640 1 spoon, 1 banana, 1 book, 50.3ms\n",
      "Speed: 1.3ms preprocess, 50.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_2638.jpg: 480x640 (no detections), 48.9ms\n",
      "Speed: 1.5ms preprocess, 48.9ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7740.jpg: 480x640 1 frisbee, 1 sports ball, 1 apple, 53.4ms\n",
      "Speed: 1.5ms preprocess, 53.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6890.jpg: 480x640 1 apple, 1 orange, 47.0ms\n",
      "Speed: 1.3ms preprocess, 47.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4739.jpg: 480x640 1 banana, 2 apples, 48.1ms\n",
      "Speed: 1.1ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_8261.jpg: 480x640 1 apple, 1 dining table, 55.4ms\n",
      "Speed: 1.1ms preprocess, 55.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6517.jpg: 480x640 1 laptop, 48.6ms\n",
      "Speed: 1.5ms preprocess, 48.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4472.jpg: 480x640 1 banana, 1 apple, 61.2ms\n",
      "Speed: 1.4ms preprocess, 61.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4843.jpg: 480x640 (no detections), 48.6ms\n",
      "Speed: 1.5ms preprocess, 48.6ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4857.jpg: 480x640 1 knife, 1 spoon, 1 apple, 47.4ms\n",
      "Speed: 1.4ms preprocess, 47.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3645.jpg: 480x640 (no detections), 45.8ms\n",
      "Speed: 1.5ms preprocess, 45.8ms inference, 0.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7557.jpg: 480x640 1 bird, 1 banana, 1 apple, 48.9ms\n",
      "Speed: 1.4ms preprocess, 48.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_2349.jpg: 480x640 1 bird, 1 banana, 50.4ms\n",
      "Speed: 1.3ms preprocess, 50.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7027.jpg: 480x640 1 apple, 55.8ms\n",
      "Speed: 1.2ms preprocess, 55.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6467.jpg: 480x640 (no detections), 50.7ms\n",
      "Speed: 1.4ms preprocess, 50.7ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_5620.jpg: 480x640 1 banana, 1 apple, 52.2ms\n",
      "Speed: 1.6ms preprocess, 52.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7786.jpg: 480x640 (no detections), 52.5ms\n",
      "Speed: 1.0ms preprocess, 52.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7355.jpg: 480x640 1 apple, 1 dining table, 51.8ms\n",
      "Speed: 1.1ms preprocess, 51.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_8099.jpg: 480x640 1 sports ball, 1 apple, 1 orange, 48.8ms\n",
      "Speed: 1.2ms preprocess, 48.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7816.jpg: 480x640 1 apple, 49.8ms\n",
      "Speed: 1.3ms preprocess, 49.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_2947.jpg: 480x640 2 apples, 50.5ms\n",
      "Speed: 1.3ms preprocess, 50.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7354.jpg: 480x640 (no detections), 49.8ms\n",
      "Speed: 1.2ms preprocess, 49.8ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6062.jpg: 480x640 1 person, 1 banana, 50.3ms\n",
      "Speed: 1.4ms preprocess, 50.3ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3913.jpg: 480x640 2 persons, 1 banana, 53.7ms\n",
      "Speed: 1.4ms preprocess, 53.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_2833.jpg: 480x640 1 apple, 1 orange, 51.5ms\n",
      "Speed: 1.6ms preprocess, 51.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7963.jpg: 480x640 2 apples, 50.1ms\n",
      "Speed: 1.6ms preprocess, 50.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_2166.jpg: 480x640 (no detections), 50.0ms\n",
      "Speed: 1.5ms preprocess, 50.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_8449.jpg: 480x640 1 knife, 1 apple, 51.4ms\n",
      "Speed: 1.3ms preprocess, 51.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6666.jpg: 480x640 1 person, 1 banana, 52.3ms\n",
      "Speed: 1.3ms preprocess, 52.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3722.jpg: 480x640 1 bench, 1 apple, 1 orange, 49.9ms\n",
      "Speed: 0.8ms preprocess, 49.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_5019.jpg: 480x640 1 sports ball, 1 apple, 53.1ms\n",
      "Speed: 1.1ms preprocess, 53.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4307.jpg: 480x640 1 apple, 64.4ms\n",
      "Speed: 1.6ms preprocess, 64.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3483.jpg: 480x640 (no detections), 50.5ms\n",
      "Speed: 1.4ms preprocess, 50.5ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4460.jpg: 480x640 1 person, 1 kite, 1 apple, 50.9ms\n",
      "Speed: 1.4ms preprocess, 50.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3870.jpg: 480x640 3 apples, 47.3ms\n",
      "Speed: 1.5ms preprocess, 47.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4892.jpg: 480x640 1 knife, 1 spoon, 1 book, 47.9ms\n",
      "Speed: 1.6ms preprocess, 47.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4138.jpg: 480x640 1 bench, 1 apple, 46.6ms\n",
      "Speed: 1.2ms preprocess, 46.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "2023-10-21 17:33:46.730 Python[71522:4250983] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6713.jpg: 480x640 1 book, 52.5ms\n",
      "Speed: 1.4ms preprocess, 52.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6854.jpg: 480x640 1 person, 1 sports ball, 1 banana, 1 apple, 52.5ms\n",
      "Speed: 1.7ms preprocess, 52.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_5636.jpg: 480x640 2 apples, 1 laptop, 48.6ms\n",
      "Speed: 1.2ms preprocess, 48.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6471.jpg: 480x640 3 apples, 50.1ms\n",
      "Speed: 1.3ms preprocess, 50.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3509.jpg: 480x640 1 apple, 1 orange, 50.9ms\n",
      "Speed: 1.4ms preprocess, 50.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_2857.jpg: 480x640 1 apple, 1 orange, 47.1ms\n",
      "Speed: 1.7ms preprocess, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_5876.jpg: 480x640 1 apple, 1 orange, 49.9ms\n",
      "Speed: 1.7ms preprocess, 49.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4995.jpg: 480x640 1 apple, 53.9ms\n",
      "Speed: 1.4ms preprocess, 53.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4639.jpg: 480x640 1 laptop, 46.7ms\n",
      "Speed: 1.3ms preprocess, 46.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4374.jpg: 480x640 1 person, 1 banana, 1 apple, 47.0ms\n",
      "Speed: 1.4ms preprocess, 47.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7669.jpg: 480x640 1 suitcase, 1 spoon, 1 cell phone, 51.5ms\n",
      "Speed: 1.8ms preprocess, 51.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4406.jpg: 480x640 3 apples, 64.1ms\n",
      "Speed: 1.2ms preprocess, 64.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3427.jpg: 480x640 1 apple, 1 orange, 56.1ms\n",
      "Speed: 1.1ms preprocess, 56.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_2739.jpg: 480x640 1 apple, 51.6ms\n",
      "Speed: 1.4ms preprocess, 51.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_5283.jpg: 480x640 1 apple, 1 vase, 53.0ms\n",
      "Speed: 0.8ms preprocess, 53.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6007.jpg: 480x640 1 apple, 51.8ms\n",
      "Speed: 0.8ms preprocess, 51.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3625.jpg: 480x640 1 person, 1 kite, 1 banana, 52.6ms\n",
      "Speed: 0.9ms preprocess, 52.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7457.jpg: 480x640 1 person, 1 banana, 1 apple, 48.1ms\n",
      "Speed: 1.6ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6991.jpg: 480x640 1 apple, 3 books, 51.7ms\n",
      "Speed: 1.4ms preprocess, 51.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6615.jpg: 480x640 2 ovens, 47.6ms\n",
      "Speed: 0.8ms preprocess, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_2467.jpg: 480x640 1 apple, 52.3ms\n",
      "Speed: 1.2ms preprocess, 52.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_5687.jpg: 480x640 1 apple, 1 dining table, 51.5ms\n",
      "Speed: 1.6ms preprocess, 51.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4566.jpg: 480x640 1 apple, 49.6ms\n",
      "Speed: 1.4ms preprocess, 49.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_5122.jpg: 480x640 1 sports ball, 2 apples, 1 orange, 52.5ms\n",
      "Speed: 1.3ms preprocess, 52.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3547.jpg: 480x640 1 apple, 49.4ms\n",
      "Speed: 0.9ms preprocess, 49.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7721.jpg: 480x640 1 banana, 50.6ms\n",
      "Speed: 1.4ms preprocess, 50.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_2868.jpg: 480x640 1 apple, 49.8ms\n",
      "Speed: 1.3ms preprocess, 49.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3753.jpg: 480x640 1 banana, 50.7ms\n",
      "Speed: 1.4ms preprocess, 50.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3948.jpg: 480x640 1 apple, 53.5ms\n",
      "Speed: 0.8ms preprocess, 53.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_7284.jpg: 480x640 (no detections), 51.2ms\n",
      "Speed: 1.7ms preprocess, 51.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_6993.jpg: 480x640 1 apple, 1 dining table, 2 laptops, 56.5ms\n",
      "Speed: 1.0ms preprocess, 56.5ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_3182.jpg: 480x640 1 banana, 1 apple, 47.1ms\n",
      "Speed: 1.5ms preprocess, 47.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/raw/Raw_Mango_0_4376.jpg: 480x640 1 apple, 1 dining table, 51.5ms\n",
      "Speed: 0.9ms preprocess, 51.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jacopouggeri/workspace/datathon/YOLO.ipynb Cell 6\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/YOLO.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m all_files:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/YOLO.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     f \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, file)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/YOLO.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     results \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(f, show\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/workspace/datathon/.venv/lib/python3.11/site-packages/ultralytics/engine/model.py:242\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mif\u001b[39;00m prompts \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor, \u001b[39m'\u001b[39m\u001b[39mset_prompts\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 242\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor\u001b[39m.\u001b[39mpredict_cli(source\u001b[39m=\u001b[39msource) \u001b[39mif\u001b[39;00m is_cli \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredictor(source\u001b[39m=\u001b[39;49msource, stream\u001b[39m=\u001b[39;49mstream)\n",
      "File \u001b[0;32m~/workspace/datathon/.venv/lib/python3.11/site-packages/ultralytics/engine/predictor.py:196\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream_inference(source, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/workspace/datathon/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[39m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[39m=\u001b[39m gen\u001b[39m.\u001b[39msend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[39m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/datathon/.venv/lib/python3.11/site-packages/ultralytics/engine/predictor.py:282\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults[i]\u001b[39m.\u001b[39msave_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir\u001b[39m.\u001b[39m\u001b[39m__str__\u001b[39m()\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshow \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplotted_img \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 282\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshow(p)\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39msave \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplotted_img \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_preds(vid_cap, i, \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir \u001b[39m/\u001b[39m p\u001b[39m.\u001b[39mname))\n",
      "File \u001b[0;32m~/workspace/datathon/.venv/lib/python3.11/site-packages/ultralytics/engine/predictor.py:331\u001b[0m, in \u001b[0;36mBasePredictor.show\u001b[0;34m(self, p)\u001b[0m\n\u001b[1;32m    329\u001b[0m     cv2\u001b[39m.\u001b[39mresizeWindow(\u001b[39mstr\u001b[39m(p), im0\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], im0\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    330\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39mstr\u001b[39m(p), im0)\n\u001b[0;32m--> 331\u001b[0m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m500\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch[\u001b[39m3\u001b[39;49m]\u001b[39m.\u001b[39;49mstartswith(\u001b[39m'\u001b[39;49m\u001b[39mimage\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39melse\u001b[39;49;00m \u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"datasets/mango/images/test/raw\"\n",
    "\n",
    "# List all files in the directory\n",
    "all_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "for file in all_files:\n",
    "    f = os.path.join(path, file)\n",
    "    results = model.predict(f, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from helper import resize_and_pad\n",
    "\n",
    "folder_type = \"train/ripe\" # test/train raw/ripe\n",
    "\n",
    "input_folder = 'datasets/mango/images/' + folder_type\n",
    "output_folder = 'datasets/mango_cut/images/' + folder_type\n",
    "confidence_threshold = 0.6  # Adjust as needed\n",
    "\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Delete all files in the output folder\n",
    "for filename in os.listdir(output_folder):\n",
    "    file_path = os.path.join(output_folder, filename)\n",
    "    if os.path.isfile(file_path):  # ensure it's a file, not a directory or other type\n",
    "        os.remove(file_path)\n",
    "\n",
    "for image_file in image_files:\n",
    "    # Load the image using cv2\n",
    "    img_path = os.path.join(input_folder, image_file)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # Generate predictions for the image\n",
    "    results = model.predict(source=img)\n",
    "    \n",
    "    # Check if any detection was made\n",
    "    if len(results[0].boxes.xyxy) == 0:\n",
    "        print(f\"Skipping {image_file} due to no detection.\")\n",
    "        continue\n",
    "\n",
    "    # Get the index of the bounding box with the highest confidence\n",
    "    max_conf_index = np.argmax(results[0].boxes.conf.cpu().numpy())\n",
    "    \n",
    "    # Check if highest confidence is above threshold\n",
    "    if results[0].boxes.conf[max_conf_index] < confidence_threshold:\n",
    "        print(f\"Skipping {image_file} due to low confidence.\")\n",
    "        continue\n",
    "    \n",
    "    # Extract and save the object with highest confidence\n",
    "    box = results[0].boxes.xyxy[max_conf_index].cpu().numpy().astype(int)\n",
    "    x1, y1, x2, y2 = box\n",
    "    cropped_img = img[y1:y2, x1:x2]\n",
    "\n",
    "    # Resize and pad\n",
    "    final_img = resize_and_pad(cropped_img)\n",
    "\n",
    "    # Save the cropped image\n",
    "    output_path = os.path.join(output_folder, f\"crop_{image_file}\")\n",
    "    cv2.imwrite(output_path, final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/ripe/Ripe_Mango_0_7546.jpg: 480x640 1 person, 2 apples, 59.3ms\n",
      "Speed: 1.3ms preprocess, 59.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "2023-10-22 00:31:17.331 Python[93421:4647387] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/ripe/Ripe_Mango_0_7156.jpg: 480x640 1 sports ball, 1 apple, 47.6ms\n",
      "Speed: 1.6ms preprocess, 47.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/ripe/Ripe_Mango_0_2990.jpg: 480x640 3 oranges, 51.1ms\n",
      "Speed: 1.6ms preprocess, 51.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/ripe/Ripe_Mango_0_4885.jpg: 480x640 1 orange, 52.2ms\n",
      "Speed: 1.8ms preprocess, 52.2ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/ripe/Ripe_Mango_0_3640.jpg: 480x640 2 apples, 51.4ms\n",
      "Speed: 2.0ms preprocess, 51.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/ripe/Ripe_Mango_0_6063.jpg: 480x640 1 orange, 49.5ms\n",
      "Speed: 1.9ms preprocess, 49.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/ripe/Ripe_Mango_0_4660.jpg: 480x640 1 sports ball, 53.4ms\n",
      "Speed: 1.9ms preprocess, 53.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "image 1/1 /Users/jacopouggeri/workspace/datathon/datasets/mango/images/test/ripe/Ripe_Mango_0_3641.jpg: 480x640 1 apple, 1 orange, 52.8ms\n",
      "Speed: 1.9ms preprocess, 52.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jacopouggeri/workspace/datathon/playground.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/playground.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         \u001b[39m# Optionally: Put the label (class) on the top of the bounding box\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/playground.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39m# label = str(results.classes[i])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/playground.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39m# cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/playground.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/playground.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m# Display the image with boxes\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/playground.ipynb#X10sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mDetected Mangoes\u001b[39m\u001b[39m'\u001b[39m, img)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/playground.ipynb#X10sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m0\u001b[39;49m)  \u001b[39m# Waits for a key press to move to the next image\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jacopouggeri/workspace/datathon/playground.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "path = \"datasets/mango/images/test/ripe\"\n",
    "\n",
    "# List all files in the directory\n",
    "all_files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n",
    "\n",
    "for file in all_files:\n",
    "    f = os.path.join(path, file)\n",
    "    \n",
    "    # Predict using the model\n",
    "    results = model.predict(f)\n",
    "    \n",
    "    # Read the image\n",
    "    img = cv2.imread(f)\n",
    "    \n",
    "    # Draw bounding boxes on the image\n",
    "    for i, box in enumerate(results[0].boxes.xyxy):\n",
    "        # Extract the bounding box coordinates\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        \n",
    "        # Draw the rectangle on the image\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green color for the rectangle\n",
    "        \n",
    "        # Optionally: Put the label (class) on the top of the bounding box\n",
    "        # label = str(results.classes[i])\n",
    "        # cv2.putText(img, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the image with boxes\n",
    "    cv2.imshow('Detected Mangoes', img)\n",
    "    cv2.waitKey(0)  # Waits for a key press to move to the next image\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
