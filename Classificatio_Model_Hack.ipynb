{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# random seeds for reproducibility\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = './datasets/mango_cut/images/'\n",
    "folder_path_ripe = img_path + 'train/ripe'\n",
    "folder_path_raw =  img_path + 'train/raw'\n",
    "\n",
    "image_files_ripe = [f for f in os.listdir(folder_path_ripe) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "image_files_raw = [f for f in os.listdir(folder_path_raw) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Loop through the image files and load each image\n",
    "\n",
    "#RIPE\n",
    "images_ripe = []\n",
    "for file_name in image_files_ripe:\n",
    "    image_path = os.path.join(folder_path_ripe, file_name)\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is not None:\n",
    "        #Convert the BGR image to RGB \n",
    "        images_ripe.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        print(f\"Failed to load {file_name}\")\n",
    "\n",
    "#RAW\n",
    "images_raw = []\n",
    "for file_name in image_files_raw:\n",
    "    image_path = os.path.join(folder_path_raw, file_name)\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is not None:\n",
    "        #Convert the BGR image to RGB \n",
    "        images_raw.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        print(f\"Failed to load {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep the dataframe and shuffle\n",
    "### Images -> X; Labels -> y\n",
    "raw : 0 <br>\n",
    "ripe : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat raw and ripe\n",
    "y = [0 for x in range(len(images_raw))] + [1 for x in range(len(images_ripe))]\n",
    "X=images_raw+images_ripe\n",
    "\n",
    "#convert from list to np.array\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "\n",
    "#Shuffle\n",
    "X_shuffled, y_shuffled = shuffle(X, y)\n",
    "\n",
    "#Train Validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (916, 640, 640, 3)\n",
      "y_train shape: (916,)\n",
      "X_Validation shape: (230, 640, 640, 3)\n",
      "y_Validation shape: (230,)\n"
     ]
    }
   ],
   "source": [
    "# Check out the data\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_Validation shape: {X_val.shape}')\n",
    "print(f'y_Validation shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X range: 0-255\n",
      "y values: [0 1]\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# range of x values\n",
    "print(f'X range: {X_train.min()}-{X_train.max()}')\n",
    "# y unique values\n",
    "print(f'y values: {np.unique(y_train)}')\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(f'Number of classes: {num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (916, 640, 640, 3)\n",
      "X_val shape: (230, 640, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# Define input image dimensions\n",
    "img_rows, img_cols, colours = 640, 640, 3\n",
    "\n",
    "# Reshape for Keras model types\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, colours)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, colours)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise: 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train range: 0.0-1.0\n"
     ]
    }
   ],
   "source": [
    "# Scale from 0-1 to 0-255\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "print(f'X_train range: {X_train.min()}-{X_train.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 640, 640, 32)      2432      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 640, 640, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 640, 640, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 320, 320, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 320, 320, 32)      0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 320, 320, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 320, 320, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 320, 320, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 160, 160, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 160, 160, 64)      0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1638400)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               209715328 \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209745473 (800.12 MB)\n",
      "Trainable params: 209745025 (800.11 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "\n",
    "CNN_model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "CNN_model.add(Conv2D(32, kernel_size=(5, 5), padding='same', input_shape=(640, 640, 3)))\n",
    "CNN_model.add(BatchNormalization())\n",
    "CNN_model.add(Activation('relu'))\n",
    "CNN_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "CNN_model.add(Dropout(0.25))\n",
    "\n",
    "# Layer 2\n",
    "CNN_model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "CNN_model.add(BatchNormalization())\n",
    "CNN_model.add(Activation('relu'))\n",
    "CNN_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "CNN_model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten\n",
    "CNN_model.add(Flatten())\n",
    "\n",
    "# Dense layers\n",
    "CNN_model.add(Dense(128))\n",
    "CNN_model.add(BatchNormalization())\n",
    "CNN_model.add(Activation('relu'))\n",
    "CNN_model.add(Dropout(0.5))\n",
    "CNN_model.add(Dense(64, activation='relu'))\n",
    "CNN_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "CNN_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 242s 8s/step - loss: 0.1638 - accuracy: 0.9378 - val_loss: 0.6683 - val_accuracy: 0.5522\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 213s 7s/step - loss: 0.0865 - accuracy: 0.9618 - val_loss: 0.8549 - val_accuracy: 0.5217\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 209s 7s/step - loss: 0.0832 - accuracy: 0.9662 - val_loss: 0.9426 - val_accuracy: 0.5217\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 213s 7s/step - loss: 0.0856 - accuracy: 0.9618 - val_loss: 0.4193 - val_accuracy: 0.8391\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 210s 7s/step - loss: 0.0669 - accuracy: 0.9705 - val_loss: 0.3585 - val_accuracy: 0.8522\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 209s 7s/step - loss: 0.0504 - accuracy: 0.9771 - val_loss: 0.3470 - val_accuracy: 0.8913\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 205s 7s/step - loss: 0.0534 - accuracy: 0.9825 - val_loss: 0.5523 - val_accuracy: 0.6957\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 200s 7s/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.2207 - val_accuracy: 0.9130\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 198s 7s/step - loss: 0.0352 - accuracy: 0.9891 - val_loss: 0.4326 - val_accuracy: 0.7348\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 197s 7s/step - loss: 0.0317 - accuracy: 0.9924 - val_loss: 0.1050 - val_accuracy: 0.9652\n"
     ]
    }
   ],
   "source": [
    "history = CNN_model.fit(X_train, y_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=10,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 9s 967ms/step - loss: 0.1050 - accuracy: 0.9652\n",
      "Validation accuracy:  0.9652174115180969\n",
      "Validation loss:  0.10498477518558502\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on the validation set\n",
    "test_loss, test_accuracy = CNN_model.evaluate(X_val, y_val)\n",
    "print(\"Validation accuracy: \", test_accuracy)\n",
    "print(\"Validation loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_ripe = img_path + 'test/ripe'\n",
    "folder_path_raw = img_path + 'test/raw'\n",
    "\n",
    "image_files_ripe = [f for f in os.listdir(folder_path_ripe) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "image_files_raw = [f for f in os.listdir(folder_path_raw) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Loop through the image files and load each image\n",
    "\n",
    "#RIPE\n",
    "images_ripe = []\n",
    "for file_name in image_files_ripe:\n",
    "    image_path = os.path.join(folder_path_ripe, file_name)\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is not None:\n",
    "        #Convert the BGR image to RGB \n",
    "        images_ripe.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        print(f\"Failed to load {file_name}\")\n",
    "\n",
    "#RAW\n",
    "images_raw = []\n",
    "for file_name in image_files_raw:\n",
    "    image_path = os.path.join(folder_path_raw, file_name)\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is not None:\n",
    "        #Convert the BGR image to RGB \n",
    "        images_raw.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        print(f\"Failed to load {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat raw and ripe\n",
    "y_test = [0 for x in range(len(images_raw))] + [1 for x in range(len(images_ripe))]\n",
    "X_test=images_raw+images_ripe\n",
    "\n",
    "#convert from list to np.array\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "#Shuffle\n",
    "X_shuffled_test, X_shuffled_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (231, 640, 640, 3)\n",
      "y_train shape: (231,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 840ms/step - loss: 39.7728 - accuracy: 0.8225\n",
      "Test accuracy:  0.822510838508606\n",
      "Test loss:  39.77281188964844\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on the validation set\n",
    "test_loss, test_accuracy = CNN_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy: \", test_accuracy)\n",
    "print(\"Test loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacopouggeri/workspace/datathon/.venv/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model\n",
    "CNN_model.save('CNN_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_model.pb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: CNN_model.pb/assets\n"
     ]
    }
   ],
   "source": [
    "# Save the entire model\n",
    "CNN_model.save('CNN_model.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.save_weights('CNN_model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
