{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the librarires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-21 21:17:51.325103: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# random seeds for reproducibility\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_ripe = './data/images/train/ripe'\n",
    "folder_path_raw = './data/images/train/raw'\n",
    "\n",
    "image_files_ripe = [f for f in os.listdir(folder_path_ripe) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "image_files_raw = [f for f in os.listdir(folder_path_raw) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Loop through the image files and load each image\n",
    "\n",
    "#RIPE\n",
    "images_ripe = []\n",
    "for file_name in image_files_ripe:\n",
    "    image_path = os.path.join(folder_path_ripe, file_name)\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is not None:\n",
    "        #Convert the BGR image to RGB \n",
    "        images_ripe.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        print(f\"Failed to load {file_name}\")\n",
    "\n",
    "#RAW\n",
    "images_raw = []\n",
    "for file_name in image_files_raw:\n",
    "    image_path = os.path.join(folder_path_raw, file_name)\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is not None:\n",
    "        #Convert the BGR image to RGB \n",
    "        images_raw.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        print(f\"Failed to load {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep the dataframe and shuffle\n",
    "### Images -> X; Labels -> y\n",
    "raw : 0 <br>\n",
    "ripe : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat raw and ripe\n",
    "y = [0 for x in range(len(images_raw))] + [1 for x in range(len(images_ripe))]\n",
    "X=images_raw+images_ripe\n",
    "\n",
    "#convert from list to np.array\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "\n",
    "#Shuffle\n",
    "X_shuffled, y_shuffled = shuffle(X, y)\n",
    "\n",
    "#Train Validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (916, 640, 640, 3)\n",
      "y_train shape: (916,)\n",
      "X_Validation shape: (230, 640, 640, 3)\n",
      "y_Validation shape: (230,)\n"
     ]
    }
   ],
   "source": [
    "# Check out the data\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'y_train shape: {y_train.shape}')\n",
    "print(f'X_Validation shape: {X_val.shape}')\n",
    "print(f'y_Validation shape: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X range: 0-255\n",
      "y values: [0 1]\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# range of x values\n",
    "print(f'X range: {X_train.min()}-{X_train.max()}')\n",
    "# y unique values\n",
    "print(f'y values: {np.unique(y_train)}')\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(f'Number of classes: {num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (916, 640, 640, 3)\n",
      "X_val shape: (230, 640, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "# Define input image dimensions\n",
    "img_rows, img_cols, colours = 640, 640, 3\n",
    "\n",
    "# Reshape for Keras model types\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, colours)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, colours)\n",
    "\n",
    "print(f'X_train shape: {X_train.shape}')\n",
    "print(f'X_val shape: {X_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalise: 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train range: 0.0-1.0\n"
     ]
    }
   ],
   "source": [
    "# Scale from 0-1 to 0-255\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_train /= 255\n",
    "X_val /= 255\n",
    "print(f'X_train range: {X_train.min()}-{X_train.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 640, 640, 32)      2432      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 640, 640, 32)     128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation (Activation)     (None, 640, 640, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 320, 320, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 320, 320, 32)      0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 320, 320, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 320, 320, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 320, 320, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 160, 160, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 160, 160, 64)      0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1638400)           0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               209715328 \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 209,745,473\n",
      "Trainable params: 209,745,025\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "\n",
    "CNN_model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "CNN_model.add(Conv2D(32, kernel_size=(5, 5), padding='same', input_shape=(640, 640, 3)))\n",
    "CNN_model.add(BatchNormalization())\n",
    "CNN_model.add(Activation('relu'))\n",
    "CNN_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "CNN_model.add(Dropout(0.25))\n",
    "\n",
    "# Layer 2\n",
    "CNN_model.add(Conv2D(64, kernel_size=(3, 3), padding='same'))\n",
    "CNN_model.add(BatchNormalization())\n",
    "CNN_model.add(Activation('relu'))\n",
    "CNN_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "CNN_model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten\n",
    "CNN_model.add(Flatten())\n",
    "\n",
    "# Dense layers\n",
    "CNN_model.add(Dense(128))\n",
    "CNN_model.add(BatchNormalization())\n",
    "CNN_model.add(Activation('relu'))\n",
    "CNN_model.add(Dropout(0.5))\n",
    "CNN_model.add(Dense(64, activation='relu'))\n",
    "CNN_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "CNN_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model.compile(optimizer='adam', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "29/29 [==============================] - 259s 9s/step - loss: 0.2549 - accuracy: 0.9105 - val_loss: 0.3647 - val_accuracy: 0.8391\n",
      "Epoch 2/10\n",
      "29/29 [==============================] - 275s 9s/step - loss: 0.1075 - accuracy: 0.9574 - val_loss: 0.1814 - val_accuracy: 0.9522\n",
      "Epoch 3/10\n",
      "29/29 [==============================] - 257s 9s/step - loss: 0.0827 - accuracy: 0.9629 - val_loss: 0.2535 - val_accuracy: 0.8957\n",
      "Epoch 4/10\n",
      "29/29 [==============================] - 260s 9s/step - loss: 0.0971 - accuracy: 0.9574 - val_loss: 0.1804 - val_accuracy: 0.9304\n",
      "Epoch 5/10\n",
      "29/29 [==============================] - 282s 10s/step - loss: 0.0704 - accuracy: 0.9640 - val_loss: 0.1816 - val_accuracy: 0.9261\n",
      "Epoch 6/10\n",
      "29/29 [==============================] - 270s 9s/step - loss: 0.0590 - accuracy: 0.9803 - val_loss: 0.1890 - val_accuracy: 0.9435\n",
      "Epoch 7/10\n",
      "29/29 [==============================] - 263s 9s/step - loss: 0.0479 - accuracy: 0.9782 - val_loss: 1.0868 - val_accuracy: 0.5391\n",
      "Epoch 8/10\n",
      "29/29 [==============================] - 251s 9s/step - loss: 0.0560 - accuracy: 0.9782 - val_loss: 2.4300 - val_accuracy: 0.5174\n",
      "Epoch 9/10\n",
      "29/29 [==============================] - 252s 9s/step - loss: 0.0413 - accuracy: 0.9847 - val_loss: 0.6256 - val_accuracy: 0.7043\n",
      "Epoch 10/10\n",
      "29/29 [==============================] - 265s 9s/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.0468 - val_accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "history = CNN_model.fit(X_train, y_train,\n",
    "                        batch_size=32,\n",
    "                        epochs=10,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 11s 1s/step - loss: 0.0468 - accuracy: 0.9826\n",
      "Validation accuracy:  0.9826086759567261\n",
      "Validation loss:  0.04678649082779884\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on the validation set\n",
    "test_loss, test_accuracy = CNN_model.evaluate(X_val, y_val)\n",
    "print(\"Validation accuracy: \", test_accuracy)\n",
    "print(\"Validation loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_ripe = './data/images/test/ripe'\n",
    "folder_path_raw = './data/images/test/raw'\n",
    "\n",
    "image_files_ripe = [f for f in os.listdir(folder_path_ripe) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "image_files_raw = [f for f in os.listdir(folder_path_raw) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Loop through the image files and load each image\n",
    "\n",
    "#RIPE\n",
    "images_ripe = []\n",
    "for file_name in image_files_ripe:\n",
    "    image_path = os.path.join(folder_path_ripe, file_name)\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is not None:\n",
    "        #Convert the BGR image to RGB \n",
    "        images_ripe.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        print(f\"Failed to load {file_name}\")\n",
    "\n",
    "#RAW\n",
    "images_raw = []\n",
    "for file_name in image_files_raw:\n",
    "    image_path = os.path.join(folder_path_raw, file_name)\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if img is not None:\n",
    "        #Convert the BGR image to RGB \n",
    "        images_raw.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        print(f\"Failed to load {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat raw and ripe\n",
    "y_test = [0 for x in range(len(images_raw))] + [1 for x in range(len(images_ripe))]\n",
    "X_test=images_raw+images_ripe\n",
    "\n",
    "#convert from list to np.array\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)\n",
    "\n",
    "#Shuffle\n",
    "X_shuffled_test, X_shuffled_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (231, 640, 640, 3)\n",
      "y_train shape: (231,)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_test.shape}')\n",
    "print(f'y_train shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 11s 1s/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Test accuracy:  1.0\n",
      "Test loss:  0.007888706400990486\n"
     ]
    }
   ],
   "source": [
    "# Evaluating on the validation set\n",
    "test_loss, test_accuracy = CNN_model.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy: \", test_accuracy)\n",
    "print(\"Test loss: \", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model\n",
    "CNN_model.save('CNN_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
